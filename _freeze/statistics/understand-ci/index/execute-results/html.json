{
  "hash": "527c9380c15b4db4a745cb98bde2122c",
  "result": {
    "markdown": "---\ntitle: \"Overlap but Significant: Understanding and Communicating Treatment Effects\"\ndate: 8/27/2025\nauthor:\n  - name: Zhaowen Guo\n    url: \"https://www.linkedin.com/in/zhaowen-guo-20535312a/\"\ntitle-block-banner: true\nformat:\n  html:\n    theme: flatly\n    code-fold: true\n    code-tools: false\n    toc: false\n    number-sections: false\nlink-citations: true\ncategories: [code, statistics, experimental design]\nimage: \"overlapped-ci.png\"\n---\n\n\n# The paradox\n\nAt a recent talk, I presented RCT results using the graph below, showing weighted and unweighted group means with 95% confidence intervals (CIs) for control and treatment. An audience raised an interesting question, \"If the error bars overlap, how can the treatment be significant?\"\n\n![](overlapped-ci.png)\n\nIt can indeed feel paradoxical at the moment because the picture invites a common heuristic: *non-overlapping 95% CIs ⇒ statistically significant*. Many people then assume the converse where *overlapping 95% CIs ⇒ not significant*. But does the converse really hold? When we see overlap, does it naturally rule out a real treatment effect?\n\n# Why overlap $\\neq$ no effect\n\nTo probe this intuition, I first simulated two-arm experiments under a modest true effect. For each trial, I drew treatment and control samples, computed 95% CIs for each group mean, and then tested the difference in means. I then tracked two outcomes: (1) cases where the group CIs overlapped and the treatment effect was significant, and (2) cases where, given overlap, the effect was still significant---a direct check on the \"*overlap ⇒ not significant\"* intuition.\n\nIn 5,000 simulated trials (n=40 per arm, true effect $\\delta$ = 0.1), I found that the two 95% CIs overlapped and the effect was significant in 22% of runs; among the overlapped cases, 25% still yielded a significant effect. Overlap, in other words, does not guarantee \"no effect\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(tidyverse)\nset.seed(123)\n\nsigned_norm_overlap <- function(ci1, ci2) {\n  avgw <- (diff(ci1) + diff(ci2)) / 2\n  (min(ci1[2], ci2[2]) - max(ci1[1], ci2[1])) / avgw\n}\n\nsim_once <- function(n = 40, delta = 0.1, sd = 1, alpha = 0.05, welch = TRUE) {\n  yc <- rnorm(n, 0, sd)\n  yt <- rnorm(n, delta, sd)\n\n  mC  <- mean(yc);  mT  <- mean(yt)\n  seC <- sd(yc) / sqrt(n); seT <- sd(yt) / sqrt(n)\n\n  tcrit <- qt(1 - alpha/2, df = n - 1)\n  ciC <- c(mC - tcrit*seC, mC + tcrit*seC)\n  ciT <- c(mT - tcrit*seT, mT + tcrit*seT)\n\n  overlap <- signed_norm_overlap(ciC, ciT)\n\n  p <- t.test(yt, yc, var.equal = !welch)$p.value\n\n  data.frame(overlap = overlap, p = p)\n}\n\nsummarize_rates <- function(B = 3000, n = 40, delta = 0.1, sd = 1, alpha = 0.05, welch = TRUE) {\n  df <- do.call(\n    rbind,\n    replicate(B, sim_once(n, delta, sd, alpha, welch), simplify = FALSE)\n  )\n\n  overlap_flag <- df$overlap > 0        \n  sig_flag     <- df$p < alpha        \n\n  # 1) P(overlap & significant)\n  k1 <- sum(overlap_flag & sig_flag); N1 <- nrow(df)\n  ci1 <- suppressWarnings(prop.test(k1, N1)$conf.int)\n  rate_uncond <- k1 / N1\n\n  # 2) P(significant | overlap)\n  N2 <- sum(overlap_flag)\n  if (N2 > 0) {\n    k2 <- sum(sig_flag[overlap_flag])\n    rate_cond <- k2 / N2\n    ci2 <- suppressWarnings(prop.test(k2, N2)$conf.int)\n  } else {\n    rate_cond <- NA_real_; ci2 <- c(NA_real_, NA_real_)\n  }\n\n  data.frame(\n    n = n,\n    delta = delta,\n    sd = sd,\n    snr = delta / sd,\n    B = B,\n    rate_overlap_sig_uncond = rate_uncond,\n    ci_uncond_lo = ci1[1], ci_uncond_hi = ci1[2],\n    rate_sig_given_overlap  = rate_cond,\n    ci_cond_lo = ci2[1], ci_cond_hi = ci2[2],\n    prop_overlap = N2 / N1\n  )\n}\n\nresults <- summarize_rates(B = 5000, n = 40, delta = 0.1)\n```\n:::\n\n\nAnalytically, this actually makes sense. Per-group CIs capture the uncertainty around each mean, but the hypothesis test targets the uncertainty of their ***difference***. For two independent groups with equal standard errors (SE), the standard error of the difference is\n\n$$\nSE_\\Delta = \\sqrt{SE^2_T + SE^2_C} = \\sqrt{2} SE\n$$\n\nFor a two-sided test at 5% significance level, we reject the null hypothesis when the estimated difference satisfies\n\n$$\n|\\hat \\Delta| > 1.96 \\times \\sqrt{2} SE \\approx 2.77 SE\n$$\n\nwhereas non-overlapping 95% CIs would require\n\n$$\n|\\hat \\Delta| > 2 \\times 1.96SE = 3.92 SE > 2.77 SE\n$$\n\nSo there still exists a band in between---large enough to reject the null, but not large enough to prevent interval overlap. That's the window where both statements are true: the group CIs overlap, yet the treatment effect is significant.\n\n# When it can happen\n\nThis naturally raises the next question: under what conditions are we more---or less---likely to observe overlapping 95% CIs still mean a real effect? We can first think about this analytically.\n\nLet the 95% CI half-widths for the two group means be\n\n$$\nh_T = 1.96 \\times SE_T \\\\\nh_C = 1.96 \\times SE_C \\\\\nd = |\\hat \\Delta| = |\\hat \\mu_T - \\hat \\mu_C|\n$$\n\nWe observe a significant difference (two-sided test at 5% significance level) when\n\n$$ d > 1.96 \\times SE_\\Delta, \\space SE_\\Delta = \\sqrt{SE_T^2 + SE_C^2} $$\n\nand non-overlapping 95% CIs when\n\n$$ d > h_T + h_C = 1.96 \\times (SE_T + SE_C) $$\n\nThen \"significant while overlapping\" happens when\n\n$$\n1.96 \\times SE_\\Delta < d < 1.96 \\times (SE_T + SE_C)\n$$\n\nStandardizing by $SE_\\Delta$, this is equivalent to\n\n$$\n1.96 < Z < \\frac{1.96}{r}, \\space r = \\frac{SE_\\Delta}{SE_T + SE_C}\n$$\n\nHere, $Z = \\frac{d}{SE_\\Delta}$ is the standardized effect estimate, which (under large n) follows approximately standard normal with mean\n\n$$\n\\theta = \\frac{\\delta}{SE_\\Delta}\n$$\n\nwhere $\\delta$ is the true difference is group means.\n\nSo the paradox window \\[1.96, 1.96/r\\] depends on\n\n-   Geometry parameter $r = SE_\\Delta / (SE_T + SE_C)$, which reflects study design (e.g. balance, variance structure, etc.\n\n-   Signal parameter $\\theta$ = $\\delta / SE_\\Delta$, which reflects effect size relative to precision\n\nEvery scenario I explore below can be understood as changing one of these parameters. These shifts determine how often the \"significant while overlapping\" phenomenon shows up in practice.\n\n## **(a) Sample size and effect size (signal parameter** $\\theta$**)**\n\nLet's start with sample size and effect size. For two groups of sizes $n_T$ and $n_C$ with common variance $\\sigma^2$,\n\n$$\nSE_\\Delta = \\sigma \\sqrt{\\frac{1}{n_T} + \\frac{1}{n_C}}\n$$\n\nSo we can rewrite\n\n$$\n\\theta = \\frac{\\delta}{\\sigma} \\cdot \\frac{1}{\\sqrt{\\frac{1}{n_T} + \\frac{1}{n_C}}}\n$$\n\nThis breaks into two parts:\n\n-   $\\frac{\\delta}{\\sigma}$ is the signal-to-noise ratio (SNR), meaning how large the effect is relative to individual-level variation\n\n-   $1/\\sqrt{1/n_T + 1/n_C}$ is the effective sample size term\n\nFor equal groups with size n, this simplifies to\n\n$$\n\\theta = \\frac{\\delta}{\\sigma}\\sqrt{\\frac{n}{2}}\n$$\n\n-   If $\\theta$ is too small, most samples fall below 1.96, and we won't observe statistical significance.\n\n-   If $\\theta$ is too large, most samples exceed the overlap cutoff 1.96/r, and the CIs won't overlap.\n\n-   Only at intermediate $\\theta$ (i.e. modest effect size and moderate n) do we often land in the narrow window \\[1.96, 1.96/r\\].\n\nTo illustrate, I simulated two groups under different combinations of per-group sample size n and standardized effect size ($\\frac{\\delta}{\\sigma}$). For each setting, I recorded whether the group CIs overlapped and the two-sample test was still significant.\n\nThe results show that, for any given sample size, the probability of seeing this paradox peaks at moderate effect sizes. Also, with larger sample sizes, smaller effects become enough to land in the paradox window.\n\n![](sample_effect.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn_grid <- c(50, 100, 150)\ndelta_grid <- seq(0, 1.0, by = 0.1)\nB <- 1000\n\nparam_grid <- tidyr::expand_grid(n = n_grid, delta = delta_grid)\n\nres <- purrr::pmap_dfr(\n  list(param_grid$n, param_grid$delta),\n  ~ summarize_rates(B = B, n = ..1, delta = ..2)\n)\n\nggplot(res, aes(x = delta, y = rate_overlap_sig_uncond,\n                color = factor(n), group = n)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Sample size per group (n)\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = \"Standardized effect size (δ / σ)\",\n    y = \"P(overlap & sig)\"\n  ) +\n  theme_minimal(base_size = 12) + \n  theme(legend.position = \"top\")\n\nggsave(\"sample_effect.png\", width = 7, height = 5, dpi = 300, units = \"in\")\n```\n:::\n\n\n## **(b) Unbalanced and heteroscesdastic groups (geometry parameter r)**\n\nSo far, we've assumed two groups of equal size and variance. But in real studies, sample sizes are often unbalanced and group variances may differ. Both of these design features affect the geometry parameter r and thus the width of the paradox window.\n\nWith equal variances\n\n$$\nSE_\\Delta = \\sigma \\sqrt{\\frac{1}{n_T} + \\frac{1}{n_C}}, \\space r = \\frac{\\sqrt{\\frac{1}{n_T} + \\frac{1}{n_C}}}{\\frac{1}{\\sqrt{n_T}} + \\frac{1}{\\sqrt{n_C}}}\n$$\n\nWhen $n_T$ = $n_C$, the ratio r simplifies to $1/\\sqrt{2}$, giving the widest possible overlap window \\[1.96, 2.77\\].\n\nAs the groups become more unbalanced (say $n_T$ $\\ll$ $n_C$), the denominator of r grows faster than the numerator, pushing r closer to 1. That shrinks the window toward a single cutoff at 1.96, making \"significant while overlapping\" less likely.\n\nIf group variances differ, the same effect occurs. The group with larger variance dominates both numerator and denominator, again driving r closer to 1 and narrowing the window.\n\nSo in practice, imbalance and heteroscedasticity both work against the paradox, while balanced, equal-variance groups maximize the chance of seeing it.\n\nIn the simulation below, I varied both group sizes (balanced vs. unbalanced) and group variances (equal vs. unequal). The results show that the paradox \"overlap while significant\" arises when the test statistic $\\theta = \\delta / SE_\\Delta$ lands in the window \\[1.96, 1.96/r\\]. Balanced, equal-variance designs maximize this window, making the paradox most visible; imbalance or heteroscedasticity sqeeze it.\n\n![](size_variance.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_once_unbal <- function(n_t, n_c, delta, sd_t = 1, sd_c = 1, alpha = 0.05) {\n  yt <- rnorm(n_t, mean = delta, sd = sd_t)\n  yc <- rnorm(n_c, mean = 0,     sd = sd_c)\n\n  mT  <- mean(yt);   mC  <- mean(yc)\n  seT <- sd(yt)/sqrt(n_t); seC <- sd(yc)/sqrt(n_c)\n\n  tcrit_t <- qt(1 - alpha/2, df = n_t - 1)\n  tcrit_c <- qt(1 - alpha/2, df = n_c - 1)\n  ciT <- c(mT - tcrit_t*seT, mT + tcrit_t*seT)\n  ciC <- c(mC - tcrit_c*seC, mC + tcrit_c*seC)\n\n  overlap <- signed_norm_overlap(ciT, ciC) > 0\n  pval <- t.test(yt, yc, var.equal = FALSE)$p.value\n  data.frame(overlap = overlap, sig = (pval < alpha))\n}\n\nr_ratio <- function(n_t, n_c, sd_t = 1, sd_c = 1) {\n  num <- sqrt(sd_t^2 / n_t + sd_c^2 / n_c)\n  den <- sd_t / sqrt(n_t) + sd_c / sqrt(n_c)\n  num / den\n}\ntheta_of <- function(delta, n_t, n_c, sd_t = 1, sd_c = 1) {\n  se_delta <- sqrt(sd_t^2 / n_t + sd_c^2 / n_c)\n  delta / se_delta\n}\n\nsummarize_rates_unbal <- function(B = 1000, n_t, n_c, delta, sd_t = 1, sd_c = 1, alpha = 0.05) {\n  sims <- bind_rows(replicate(B, sim_once_unbal(n_t, n_c, delta, sd_t, sd_c, alpha), simplify = FALSE))\n\n  overlap_flag <- sims$overlap\n  sig_flag     <- sims$sig\n\n  # 1) P(overlap & sig)\n  k1 <- sum(overlap_flag & sig_flag); N1 <- nrow(sims)\n  ci1 <- suppressWarnings(prop.test(k1, N1)$conf.int)\n  rate_uncond <- k1 / N1\n\n  # 2) P(sig | overlap)\n  N2 <- sum(overlap_flag)\n  if (N2 > 0) {\n    k2 <- sum(sig_flag[overlap_flag])\n    rate_cond <- k2 / N2\n    ci2 <- suppressWarnings(prop.test(k2, N2)$conf.int)\n  } else {\n    rate_cond <- NA_real_; ci2 <- c(NA_real_, NA_real_)\n  }\n\n  data.frame(\n    n_t = n_t, n_c = n_c, sd_t = sd_t, sd_c = sd_c,\n    delta = delta,\n    theta = theta_of(delta, n_t, n_c, sd_t, sd_c),\n    r = r_ratio(n_t, n_c, sd_t, sd_c),\n    B = B,\n    rate_overlap_sig_uncond = rate_uncond,\n    ci_uncond_lo = ci1[1], ci_uncond_hi = ci1[2],\n    rate_sig_given_overlap  = rate_cond,\n    ci_cond_lo = ci2[1], ci_cond_hi = ci2[2],\n    prop_overlap = N2 / N1\n  )\n}\n\ntheta_grid <- seq(1, 3, by = 0.1)\nB <- 1000\nscen <- scenarios %>%\n  mutate(se_delta = sqrt(sd_t^2 / n_t + sd_c^2 / n_c),\n         r       = r_ratio(n_t, n_c, sd_t, sd_c),\n         z_lo    = 1.96,\n         z_hi    = 1.96 / r)\n\nparam_grid <- scen %>% crossing(theta = theta_grid)\n\nres_theta <- pmap_dfr(\n  list(param_grid$label, param_grid$n_t, param_grid$n_c,\n       param_grid$sd_t,  param_grid$sd_c, param_grid$theta, param_grid$se_delta),\n  function(label, n_t, n_c, sd_t, sd_c, theta, se_delta) {\n    delta <- theta * se_delta\n    out <- summarize_rates_unbal(B = B, n_t = n_t, n_c = n_c,\n                                 delta = delta, sd_t = sd_t, sd_c = sd_c)\n\n    out$label <- label\n    out$theta <- theta\n    out$z_lo  <- 1.96\n    out$z_hi  <- 1.96 / out$r\n    out\n  }\n)\n\nx_min <- min(res_theta$theta)\nx_max <- max(win$z_hi) + 0.1\n\nggplot(res_theta, aes(theta, rate_overlap_sig_uncond)) +\n  geom_rect(data = distinct(res_theta, label, z_lo, z_hi),\n            aes(xmin = z_lo, xmax = z_hi, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, alpha = 0.12) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 1.6) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    subtitle = \"Shaded band is the paradox window [1.96, 1.96/r] per scenario\",\n    x = expression(theta == delta / SE[Delta]),\n    y = \"P(overlap & sig)\"\n  ) +\n  facet_wrap(~ label, ncol = 2) +\n  theme_minimal(base_size = 12)\n\nggsave(\"size_variance.png\", width = 7, height = 5, dpi = 300, units = \"in\")\n```\n:::\n\n\n# Best practices for communication\n\nThe paradox of \"overlap but significant\" highlights why careful communication of treatment effects matters. Here are some practices I've found to help avoid this trap:\n\n-   Present a CI for the treatment effect, not just per-group means\n\n    The main inferential question is about the difference, not the groups in isolation. A CI around that difference makes the evidence explicit. If we also want to display group means with their own CIs, we need to be clear that inference is based on the difference CI. A good option is to overlay or annotate the effect estimate on the same figure, so readers can't miss it.\n\n-   Keep covariate adjustment consistent\n\n    Covariate adjustment (e.g. via regressions) reduces residual variance, often narrowing narrows the treatment effect's CI. But inconsistency creates confusion: if we report raw, unadjusted group means alongside an adjusted treatment effect, the numbers won't line up. The best practice is to present model-adjusted group means with their CIs and the adjusted treatment effect from the same model.\n\n-   Use alternatives to group error bars when appropriate\n\n    Bar plots or mean plots with group error bars are familiar but can mislead, because audiences might put the focus on overlap instead of the treatment effect. For clearer communication, we can consider **forest plots**, where treatment effects are shown as dots with horizontal CIs against a zero line; **difference plots** in multi-arm studies, which place all contrasts relative to control; or **side-by-side means with annotated differences** if we want to preserve group context but highlight the comparison.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}